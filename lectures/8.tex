\chapter{Анализ звука}

Лектор: Илья Шамов

\section{Коротко о звуке}

Применение машинного обучения в анализе звука:
\begin{itemize}
    \item Классификация аудио
    \item Распознавание речи
    \item Удаление шума и улучшение качества аудио
    \item Получение информации об аудио (классификация музыкальных инструментов или настроения)
    \item Синтез речи, музыки
\end{itemize}

Звук происходит из-за вибраций различных объектов. Эти вибрации заставляют молекулы воздуха осциллировать и собираться в группы. Именно этот процесс изменяет плотность молекул воздухе (изменение воздушного давления), порождая звуковые волны.\newline
Звуковой файл на любом вычислительном устройстве хранится как список или списки чисел. У каждого аудио-файла есть следующие мета-параметры:
\begin{itemize}
    \item Количество каналов (например, моно или стерео)
    \item Частота дискретизации (sampling rate) --- число измерений звука в секунду
\end{itemize}

\begin{remark}
    Чем выше частота звука (не путать с частотой дискретизации) --- тем выше звук мы воспринимаем.
\end{remark}

\begin{remark}
    Две различные частоты воспринимаются человеком одинаково, если они различаются менее чем на наименьшую ближайшую степень двойки.
\end{remark}

Для работы со звуком полезно помнить о том, что разные живые существа воспринимают звук в разном диапазоне:
\begin{itemize}
    \item Человек: 20 -- 20'000 Гц
    \item Слон: 14 -- 12'000 Гц
    \item Кот: 48 -- 75'000 Гц
    \item Собака: 64 -- 45'000 Гц
    \item Мышь: 1'000 -- 70'000 Гц
    \item Летучая мышь: 7'000 -- 200'000 Гц
\end{itemize}

\begin{remark}
    В этом списке кроется ответ, почему все современные аудио-носители используют частоту дискретизации равную 44100 или 48000.
\end{remark}

\begin{definition}
    \textbf{Частота Найквиста} --- верхняя граница на частоту, которая может быть закодирована с использованием какой либо частоты дискретизации ($SR$) без серьезных артефактов:
    \[
        f_k=\dfrac{SR}{2}.
    \]
    Для 44'100 получаем 22'050, что чуть больше, чем 20'000
\end{definition}

\begin{remark}
    На практике, очень не рекомендуется использовать частоты, которые превышают частоту Найквиста, так как преобразования, направленные на работу с аудио будут показывать некорректное поведение.
\end{remark}

\section{Признаковое описание аудио-сэмплов}

Если работать с сырым аудио файлом как с признаковым описанием, то мы можем в какой-то момент столкнуться с проблемой, когда у аудио-файлов разной длины разная размерность признакового описания. В связи с этим нам необходимо разработать более робастные (выбросоустойчивые) инструменты признакового представления для аудио.\newline
\textbf{Основные пространства для формирования признаков для аудио}:
\begin{enumerate}
    \item \textbf{Time domain}: Признаки этой группы извлекают данные напрямую из аудио-сигнала. Работа идет в пространстве "Время-Амплитуда".
    \item \textbf{Frequency domain}: Для этих признаков характерен переход из пространства "Время-Амплитуда" в пространство "Частота - Сила (Magnitude)". Самый очевидный пример такого признака это преобразование Фурье, которое переводит аудио-файл в в частотное пространство, с которым уже можно работать как с признаковым описанием. Однако, самый важный недостаток такого подхода заключается в том, что мы полностью избавляемся от привязки ко времени, что делает недоступным для нас анализ определённой части аудио-сигнала.
    \item \textbf{Time-frequency domain}:
    \begin{itemize}
        \item Спектрограммы
        \item Спектрограммы Мела
        \item MFCC (Mel Frequency Cepstral Coefficients)
        \item Constant Q-transform
    \end{itemize}
\end{enumerate}

\begin{definition}
    \textbf{Преобразование Фурье}  --- преобразование, которое позволяет разбить аудио-сигнал на компоненты разных частот и посчитать их амплитуду. В Python реализовано в \texttt{scipy.fft.fft} и \texttt{scipy.fft.fftfreq}.
\end{definition}

\begin{definition}
    \textbf{Спектрограмма} --- изображение (тепловая карта), показывающее зависимость спектральной плотности мощности сигнала от времени. Спектрограммы применяются для идентификации речи, анализа звуков животных и так далее. Оси $x$, $y$, $z$ спектрограммы описывают время, частоту и магнитуду соответственно.
\end{definition}

Параметры, требуемые для построения спектрограммы:
\begin{itemize}
    \item Величину окна
    \item Величину сдвига
    \item Частоту дискретизации (берется из мета-информации к аудио-файлу).
\end{itemize}

\begin{remark}
    Для отображения спектрограммы можно использовать функцию\newline\texttt{librosa.display.specshow}.
\end{remark}

\begin{definition}
    \textbf{Спектрограммы Мела} -- модификация спектрограммы, которая учитывает от факт, что человеческое ухо не может отличать некоторые частоты друг от друга. Примерная формула восприятия частот (Mel scale):
    \[
        M=1125\cdot\ln\left(1+\dfrac{f}{700}\right)
    \]
\end{definition}

\begin{remark}
    Для построения спектрограммы Мела можно использовать функцию\newline\texttt{librosa.feature.melspectrogram}.
\end{remark}

\begin{definition}
    \textbf{MFCC} (\textit{Mel Frequency Cepstral Coefficients}) --- мел-кепстральные коэффициенты. Определяются следующим алгоритмом:
    \begin{enumerate}
        \item Вычисляется спектрограмма Мела,
        \item Спектрограмма Мела поэлементно логарифмируется,
        \item Вычисляется дискретное косинусное преобразование (Discrete Cosine Transform, DCT),
        \item Полученные значения амплитуд от полученного спектра являются MFCC.
    \end{enumerate}
\end{definition}

\begin{remark}
    Ось $y$ на MFCC --- это коэффициенты (безразмерная величина).
\end{remark}

\begin{remark}
    Размерность MFCC значительно меньше, чем у спектрограмм.
\end{remark}

\begin{remark}
    Для построения MFCC можно использовать функцию \texttt{librosa.feature.mfcc}.
\end{remark}
